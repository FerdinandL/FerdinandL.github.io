<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="figs/stanford_tree2.png">
  <title>Ferdinand Legros</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>

      <!-- ABOUT -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="75%" valign="middle">
        <p align="center">
          <name>Ferdinand Legros</name>
          <br>
        </p>
        <heading>About me</heading>
        <p style="text-align:justify">I am motivated by solving high-impact problems with cutting-edge AI algorithms.
        </p>

        <p style="text-align:justify">
        I currently work at <a href="https://ambient.ai/">Ambient AI</a> which aims to detect security incidents in real time from camera streams with deep learning algorithms while preserving privacy. As a Staff Applied Research Scientist, I enjoy working as an individual contributor and a team lead, alternating between quick AI prototyping, shipping production software, and designing & implementing the company AI roadmap.
        </p>

        <p style="text-align:justify">
        Previously, I spent time in the Perception team of <a href="https://x.company/projects/tidal/">Tidal</a> at <a href="https://x.company/">X</a> - formerly Google [X], at <a href="https://www.linkedin.com/">LinkedIn</a> as a Machine Learning research intern, and at <a href="https://www.bcg.com">The Boston Consulting Group</a> as a data scientist and consulting intern.
        </p>

        <p style="text-align:justify">
        I earned a MSCS from Stanford where I did research in three AI labs. I worked on Speech Recognition at the <a href="https://stanfordmlgroup.github.io/">Stanford Machine Learning Group</a>, directed by <a href="http://www.andrewng.org/">Andrew Ng</a>, I researched in Computer Vision at the <a href="http://cvgl.stanford.edu/index.html">Stanford Computational Vision and Geometry Lab</a> led by <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a>, and developed AI applications for Healthcare at the <a href="http://mobilize.stanford.edu/">Mobilize Center</a> headed by <a href="https://profiles.stanford.edu/scott-delp">Scott L. Delp</a>. Previously I explored spatio-temporal statistics research at NYU under <a href="https://vgc.poly.edu/~juliana/">Juliana Freire</a> from the <a href="https://cds.nyu.edu/">Center for Data Science</a> at <a href="https://www.nyu.edu/">NYU</a>, and studied at <a href="https://www.polytechnique.edu/">Ecole Polytechnique</a> in France.
        </p>

        <p align=center>
          <a href="docs/Resume_Ferdinand_Legros.pdf">Resume</a> &nbsp|&nbsp
          <a href="https://github.com/FerdinandL">GitHub</a> &nbsp|&nbsp
          <a href="https://www.linkedin.com/in/ferdinand-legros/"> LinkedIn </a> &nbsp|&nbsp
          fra.lgs [at] gmail.com
          <!-- <a href="TODO">Google Scholar</a> &nbsp/&nbsp -->
        </p>
        </td>
        <td width="25%">
        <img src="figs/headshot_circle.png">
        </td>
      </tr>
      </table>

      <!-- RESEARCH -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          I am interested in how machine learning and statistics can enhance machine perception. Here are research projects I took part in and the associated publications.
          </p>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr>
      <td width="25%">
        <div class="one">
        <img src='figs/carnet_pull.png'>
        </div>
      </td>
      <td valign="top" width="75%">
        <p><a href="docs/carnet_ECCV_vF.pdf">
          <papertitle>CAR-Net: Clairvoyant Attentive Recurrent Networks</papertitle></a><br>
          <a href="https://www.linkedin.com/in/amirabs/">A. Sadeghian</a>, <strong>F. Legros*</strong>, <a href="https://maximevo.github.io/">M. Voisin*</a>, R. Vessel, <a href="http://web.stanford.edu/~alahi/">A. Alahi</a>, <a href="http://cvgl.stanford.edu/silvio/">S. Savarese</a> <br>
          <em>Computer Vision and Pattern Recognition (ECCV) Paper</em>, 2018 <br>
          <p style="text-align:justify">Our method predicts the future motion of a car from past positions and top-down views of the navigation environment, e.g. a racing circuit. We developed a hybrid attention mechanism combining <a href="https://arxiv.org/abs/1502.03044">soft attention </a> and <a href="https://arxiv.org/abs/1502.04623">DRAW attention</a> methods. Our technique is state-of-the-art, allows to visualize the elements of the navigation scene that led to the prediction, and could lead to applications in drone piloting or surveillance. Code to be released soon.</p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="figs/cp_network.png" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="docs/CP_paper.txt">
          <papertitle>Hamstring Surgery Outcome Prediction with Linear Continuous Bayesian Networks</papertitle>
          </a>
          <br>
          <strong>F. Legros</strong>, <a href="http://www.cs.cmu.edu/~mfiterau/">M. Fiterau</a>, <a href="http://nmbl.stanford.edu/people/jen-hicks/">J. Hicks</a>,
          <a href="https://www.gillettechildrens.org/care-team/michael-schwartz-phd-clinical-scientist">M. Schwartz</a>, <a href="https://profiles.stanford.edu/scott-delp">S.L. Delp</a><br>
          <em>NIPS Symposium on Interpretable Machine Learning</em>, 2017<br>
          <em><a href="https://bigdata.stanford.edu/">Big Data for Biomedicine</a></em>, 2017<br>
          <a href="docs/NIPS_poster_vF.pdf">Poster</a>
        </p>
        <p style="text-align:justify">Detecting favorable hamstring surgery candidates among patients with Cerebral Palsy, a neuro-motor condition. We built a Bayesian Network model which provides an interpretable graph of variables and computes predictions of post-surgical patient state from a small number of variables. Using the system's predictions to retrospectively recommend patients for surgery led to increased prediction compared to the surgery decisions of the clinical team. Working on a journal paper, code and paper not released yet.<br></p>
        </td>
      </tr>

      <tr>
      <td width="25%">
        <div class="one">
        <img src='figs/NYU_event.png'>
        </div>
      </td>
      <td valign="top" width="75%">
        <p><a href="docs/20160921_Event_Detection_Report_FLegros.pdf">
          <papertitle>Spatio-temporal Event Detection in NYC taxi data</papertitle></a><br>
          <strong>F. Legros</strong>, <a href="http://www.harishd.com/home/"> H. Doraiswamy</a>, <a href="https://vgc.poly.edu/~juliana/">J. Freire</a>, <a href="https://www.cs.cmu.edu/~neill/">D.B. Neill</a>
          <br>
          <em>Research report</em> &nbsp/&nbsp <a href="https://github.com/FerdinandL/event_detection">Code</a>, 2016  <br>
          <p style="text-align:justify">Surveyed spatio-temporal anomaly detection methods and contributed to bridge the gap between theory and application in the field by extensive experiments with state-of-the-art methods. After showing how all techniques could be seen as a combination of essential blocks (space-time modeling, anomaly extension definition, baseline definition...), we illustrated the impact of key technique design choices on the anomalies detected on a NYC taxi density dataset. </p>
        </td>
      </tr>

      <tr>
      <td width="25%">
        <div class="one">
        <img src='figs/spectro.jpg'>
        </div>
      </td>
      <td valign="top" width="75%">
        <p>
          <papertitle>Sentiment detection from audio recordings</papertitle><br>
          <strong>F. Legros</strong>, <a href="https://cs.stanford.edu/~zxie/">Z. Xie</a>, <a href="http://www.andrewng.org/">A. Ng</a><br>
          <em>Ongoing project</em>, 2018<br>
          <p style="text-align:justify">Investigating Deep Learning techniques for audio sentiment understanding. Challenges are the presence of multiple speakers and the high audio length. I leverage emotion recognition techniques from speech literature and I work on jointly learning speech and language cues for sentiment understanding. The project is part of a global effort of an industry partner to develop general audio intelligence.</p>
        </td>
      </tr>

      </table>

      <!-- COURSE PROJECTS -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Course Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="figs/fakenews_logo.png" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="docs/fakenews_challenge.pdf">
          <papertitle>Stance Detection for the Fake News Challenge with Attention and Conditional Encoding</papertitle>
          </a>
          <br>
          <strong>F. Legros*</strong>, <a href="http://https://www.linkedin.com/in/oskartriebe/">O. Triebe*</a>, <a href="https://www.linkedin.com/in/stephen-pfohl-531b52a2/">S. Pfhol*</a>
          <br>
          <em>Project report</em> &nbsp/&nbsp <a href="docs/fakenews_poster.pdf">Poster</a>, 2017<br>
        <p style="text-align:justify">
          Detecting whether an input article agreed, disagreed or was neutral regarding various stances - e.g. "Prime Minister flew to Europe last week". Achieved accuracy of 80.8% with conditional LSTM after tackling long sequence challenge with Attention mechanism and class imbalance issues. Work was part of the <a href="http://www.fakenewschallenge.org/">Fake News Challenge</a>. Code to be released soon.
        </p>
        </p>
        </td>
      </tr>
      </table>

      <!-- TEACHING -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching</heading>
        <p>In Fall 2017 was a Teaching Assistant for Andrew Ng and Dan Boneh's class <a href="http://cs229.stanford.edu/">CS229 Machine Learning</a>.</p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          <a href="https://jonbarron.info/">Template</a>
	    </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
